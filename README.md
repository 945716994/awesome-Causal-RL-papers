# awesome-Causal-RL-papers
Here is a list of papers related to causal reinforcement learning, and I hope you can submit relevant missing papers in the issue.

# Survey
- [1] Zeng, Y., Cai, R., Sun, F., Huang, L., & Hao, Z. (2023). A Survey on Causal Reinforcement Learning. arXiv preprint arXiv:2302.05209.
- [2] Deng Z, Jiang J, Long G, et al. Causal Reinforcement Learning: A Survey[J]. arXiv preprint arXiv:2307.01452, 2023.

# Single-Agent RL
- [1] Li M, Yang M, Liu F, et al. Causal world models by unsupervised deconfounding of physical dynamics[J]. arXiv preprint arXiv:2012.14228, 2020.
- [2] Liu Y R, Huang B, Zhu Z, et al. Learning World Models with Identifiable Factorization[J]. arXiv preprint arXiv:2306.06561, 2023.
- [3] Zhu D, Li L E, Elhoseiny M. CausalDyna: Improving Generalization of Dyna-style Reinforcement Learning via Counterfactual-Based Data Augmentation[J]. 2021.
- [4] Zholus A, Ivchenkov Y, Panov A. Factorized world models for learning causal relationships[C]//ICLR2022 Workshop on the Elements of Reasoning: Objects, Structure and Causality. 2022.
- [5] Lu C, Huang B, Wang K, et al. Sample-efficient reinforcement learning via counterfactual-based data augmentation[J]. arXiv preprint arXiv:2012.09092, 2020.
- [6] Wang Z, Xiao X, Xu Z, et al. Causal dynamics learning for task-independent state abstraction[J]. arXiv preprint arXiv:2206.13452, 2022.
- [7] Pitis S, Creager E, Mandlekar A, et al. Mocoda: Model-based counterfactual data augmentation[J]. Advances in Neural Information Processing Systems, 2022, 35: 18143-18156.
- [8] Huang B, Lu C, Leqi L, et al. Action-sufficient state representation learning for control with structural constraints[C]//International Conference on Machine Learning. PMLR, 2022: 9260-9279.
- [9] Huang B, Feng F, Lu C, et al. AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning[C]//International Conference on Learning Representations. 2021.
- [10] Feng F, Huang B, Zhang K, et al. Factored adaptation for non-stationary reinforcement learning[J]. Advances in Neural Information Processing Systems, 2022, 35: 31957-31971.
- [11] Lee T E, Zhao J A, Sawhney A S, et al. Causal reasoning in simulation for structure and transfer learning of robot manipulation policies[C]//2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2021: 4776-4782.
- [12] Zhang A, Lyle C, Sodhani S, et al. Invariant causal prediction for block mdps[C]//International Conference on Machine Learning. PMLR, 2020: 11214-11224.
- [13] Seitzer M, Schölkopf B, Martius G. Causal influence detection for improving efficiency in reinforcement learning[J]. Advances in Neural Information Processing Systems, 2021, 34: 22905-22918.
- [14] Wang X, Liu Y, Song X, et al. CaMP: Causal Multi-policy Planning for Interactive Navigation in Multi-room Scenes[C]//Thirty-seventh Conference on Neural Information Processing Systems. 2023.
- [15] Ding W, Lin H, Li B, et al. Generalizing goal-conditioned reinforcement learning with variational causal reasoning[J]. Advances in Neural Information Processing Systems, 2022, 35: 26532-26548.
- [16] Oberst M, Sontag D. Counterfactual off-policy evaluation with gumbel-max structural causal models[C]//International Conference on Machine Learning. PMLR, 2019: 4881-4890.
- [17] Park J, Seo Y, Liu C, et al. Object-aware regularization for addressing causal confusion in imitation learning[J]. Advances in Neural Information Processing Systems, 2021, 34: 3029-3042.
- [18] Bica I, Jarrett D, van der Schaar M. Invariant causal imitation learning for generalizable policies[J]. Advances in Neural Information Processing Systems, 2021, 34: 3952-3964.
- [19] Zhang P, Liu F, Chen Z, et al. Deep Reinforcement Learning with Causality-based Intrinsic Reward[J]. 2020.
- [20] Mesnard T, Weber T, Viola F, et al. Counterfactual credit assignment in model-free reinforcement learning[J]. arXiv preprint arXiv:2011.09464, 2020.
- [21] Li H, Principe J. Speeding Up Reinforcement Learning by Exploiting Causality in Reward Sequences[C]//2021 International Joint Conference on Neural Networks (IJCNN). IEEE, 2021: 1-6.
- [22] Pitis S, Creager E, Garg A. Counterfactual data augmentation using locally factored dynamics[J]. Advances in Neural Information Processing Systems, 2020, 33: 3976-3990.
- [23] Eghbal-zadeh H, Henkel F, Widmer G. Learning to infer unseen contexts in causal contextual reinforcement learning[J]. Proceedings of the Self-Supervision for Reinforcement Learning, 2021.
- [24] Herlau T, Larsen R. Reinforcement learning of causal variables using mediation analysis[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2022, 36(6): 6910-6917.
- [25] Lu C, Hernández-Lobato J M, Schölkopf B. Invariant causal representation learning for generalization in imitation and reinforcement learning[C]//ICLR2022 Workshop on the Elements of Reasoning: Objects, Structure and Causality. 2022.
- [26] Li Y, Zhang D, Yin F, et al. Cleaning robot operation decision based on causal reasoning and attribute learning[C]//2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2020: 6878-6885.
- [27] Cao Y, Li B, Li Q, et al. Reasoning Operational Decisions for Robots via Time Series Causal Inference[C]//2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2021: 6124-6131.
- [28] Sun H, Wang T. Toward Causal-Aware RL: State-Wise Action-Refined Temporal Difference[J]. arXiv preprint arXiv:2201.00354, 2022.
- [29] Mutti M, De Santi R, Rossi E, et al. Provably efficient causal model-based reinforcement learning for systematic generalization[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2023, 37(8): 9251-9259.
- [30] Gasse M, Grasset D, Gaudron G, et al. Causal reinforcement learning using observational and interventional data[J]. arXiv preprint arXiv:2106.14421, 2021.
- [31] Lee T E, Zhao J A, Sawhney A S, et al. Causal reasoning in simulation for structure and transfer learning of robot manipulation policies[C]//2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2021: 4776-4782.
- [32] Lee T E, Vats S, Girdhar S, et al. SCALE: Causal Learning and Discovery of Robot Manipulation Skills using Simulation[C]//7th Annual Conference on Robot Learning. 2023.
- [33] Liang J, Boularias A. Learning Transition Models with Time-delayed Causal Relations[C]//2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2020: 8087-8093.
- [34] Buesing L, Weber T, Zwols Y, et al. Woulda, coulda, shoulda: Counterfactually-guided policy search[J]. arXiv preprint arXiv:1811.06272, 2018.
- [35] Yang C H H, Danny I, Hung T, et al. Causal inference q-network: Toward resilient reinforcement learning[C]//Self-Supervision for Reinforcement Learning Workshop-ICLR 2021. 2021.
- [36] Rezende D J, Danihelka I, Papamakarios G, et al. Causally correct partial models for reinforcement learning[J]. arXiv preprint arXiv:2002.02836, 2020.
- [37] Learning Causal Dynamics Models in Object-Oriented Environments
  - key: Objected-Oriented MDP (FMDP), Object-Oriented Causal Graph， Model-based
  - **summary_CN**: 从MDP场景扩展到了FMDP，假设环境中存在不同类型的对象，也就是说Agent接收到的State由环境中各个对象的属性组成。传统的CRL方法会直接在属性层面进行因果关系发现，这种方法在变量少的时候表现不错，但是随着变量（对象）的增加，其开销会呈指数增长，于是作者提出可以class-level的角度去做因果发现然后再学习动力学模型，由原来的Causal dynamic model变为Object Oriented Causal Dynamic Model，从而大大缩小因果发现的开销并且对于对象数量的增加有一定的扩展性（注意如果是对象类型增加了，时间开销依然会增加）。
对于面向对象的因果图(Object Oriented Causal Graph)的发现，作者依然是使用具有理论保证的条件独立性测试去做（实现方式是通过条件互信息CMI）。 假设有两种类型的对象，且每一种类型的对象有100个，那么现在只需要做类内（同一种类型对象）属性因果关系发现以及类间（不同类型对象）属性间因果关系发现即可。


# Multi-Agent RL
- [1] Grimbly S J, Shock J, Pretorius A. Causal multi-agent reinforcement learning: Review and open problems[J]. arXiv preprint arXiv:2111.06721, 2021.


# Other direction
- [1] Baradel F, Neverova N, Mille J, et al. Cophy: Counterfactual learning of physical dynamics[J]. arXiv preprint arXiv:1909.12000, 2019.
- [2] Sancaktar C, Blaes S, Martius G. Curious exploration via structured world models yields zero-shot object manipulation[J]. Advances in Neural Information Processing Systems, 2022, 35: 24170-24183.
- [3] Li Z, Zhu X, Lei Z, et al. Deconfounding Physical Dynamics with Global Causal Relation and Confounder Transmission for Counterfactual Prediction[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2022, 36(2): 1536-1545.
- [4] What If You Were Not There? Learning Causally-Aware Representations of Multi-Agent Interactions (ICLR 2024 open review)
  - key: Multi-agent forecasting, Causal effect， sim-to-real
  - link: https://openreview.net/forum?id=viJlKbTfbb
  - **summary_CN**: 本文的核心思想一句话说就是希望学习到的表征不仅能包含Direct causal agent对ego agent的causal effect,也希望可以包含Indirect causal agent对ego agent的causal effect（举个例子，你开车只看到了前面有个公交车，而公交车前面有个自行车，那么要预测你的开车轨迹不仅仅要考虑公交车还需要考虑自行车）。 这样学到的表征才能对扰动足够鲁棒，可以进行长时间步的rollout，可以快速的对新环境进行适应（前提是表征捕获到的因果机制在新环境也是相同的，Invariant Causal mechanism）。作者首先是根据一定的规则构造了反事实的数据集，并根据causal effect(paper中的公式2）对数据集中除了Ego agent以外的agent定义了三种agent：Non-causal agent、Direct causal agent、Indirect causal agent. 作者认为，如果agent $i$，$j$在场景A中的对于ego agent的causal effect $\epsilon_i$ < $\epsilon_j$，那么其在反事实场景中其causal effect也具有类似的关系。通过这样的直觉，作者分别制定了Causal Contrastive Learning以及Causal Ranking Learning两种学习方式去学习期望的表征。最终在in-distribution和OOD的实验下验证了其所提方法的有效性。

# benchmark
- [1] Ahmed O, Träuble F, Goyal A, et al. Causalworld: A robotic manipulation benchmark for causal structure and transfer learning[J]. arXiv preprint arXiv:2010.04296, 2020.

# Book
- [1] Luczkow V. Structural Causal Models for Reinforcement Learning[M]. McGill University (Canada), 2021.


# awesome-Causal-RL-papers
Here is a list of papers related to causal reinforcement learning, and I hope you can submit relevant missing papers in the issue.

# Survey
[1] Zeng, Y., Cai, R., Sun, F., Huang, L., & Hao, Z. (2023). A Survey on Causal Reinforcement Learning. arXiv preprint arXiv:2302.05209.
[2] Deng Z, Jiang J, Long G, et al. Causal Reinforcement Learning: A Survey[J]. arXiv preprint arXiv:2307.01452, 2023.

# Single-Agent RL
[1] Li M, Yang M, Liu F, et al. Causal world models by unsupervised deconfounding of physical dynamics[J]. arXiv preprint arXiv:2012.14228, 2020.
[2] Liu Y R, Huang B, Zhu Z, et al. Learning World Models with Identifiable Factorization[J]. arXiv preprint arXiv:2306.06561, 2023.
[3] Zhu D, Li L E, Elhoseiny M. CausalDyna: Improving Generalization of Dyna-style Reinforcement Learning via Counterfactual-Based Data Augmentation[J]. 2021.
[4] Zholus A, Ivchenkov Y, Panov A. Factorized world models for learning causal relationships[C]//ICLR2022 Workshop on the Elements of Reasoning: Objects, Structure and Causality. 2022.
[5] Lu C, Huang B, Wang K, et al. Sample-efficient reinforcement learning via counterfactual-based data augmentation[J]. arXiv preprint arXiv:2012.09092, 2020.
[6] Wang Z, Xiao X, Xu Z, et al. Causal dynamics learning for task-independent state abstraction[J]. arXiv preprint arXiv:2206.13452, 2022.
[7] Pitis S, Creager E, Mandlekar A, et al. Mocoda: Model-based counterfactual data augmentation[J]. Advances in Neural Information Processing Systems, 2022, 35: 18143-18156.
[8] Huang B, Lu C, Leqi L, et al. Action-sufficient state representation learning for control with structural constraints[C]//International Conference on Machine Learning. PMLR, 2022: 9260-9279.
[9] Huang B, Feng F, Lu C, et al. AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning[C]//International Conference on Learning Representations. 2021.
[10] Feng F, Huang B, Zhang K, et al. Factored adaptation for non-stationary reinforcement learning[J]. Advances in Neural Information Processing Systems, 2022, 35: 31957-31971.
[11] Lee T E, Zhao J A, Sawhney A S, et al. Causal reasoning in simulation for structure and transfer learning of robot manipulation policies[C]//2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2021: 4776-4782.
[12] Zhang A, Lyle C, Sodhani S, et al. Invariant causal prediction for block mdps[C]//International Conference on Machine Learning. PMLR, 2020: 11214-11224.
[13] Seitzer M, Schölkopf B, Martius G. Causal influence detection for improving efficiency in reinforcement learning[J]. Advances in Neural Information Processing Systems, 2021, 34: 22905-22918.
[14] Wang X, Liu Y, Song X, et al. CaMP: Causal Multi-policy Planning for Interactive Navigation in Multi-room Scenes[C]//Thirty-seventh Conference on Neural Information Processing Systems. 2023.
[15] Ding W, Lin H, Li B, et al. Generalizing goal-conditioned reinforcement learning with variational causal reasoning[J]. Advances in Neural Information Processing Systems, 2022, 35: 26532-26548.
[16] Oberst M, Sontag D. Counterfactual off-policy evaluation with gumbel-max structural causal models[C]//International Conference on Machine Learning. PMLR, 2019: 4881-4890.
[17] Park J, Seo Y, Liu C, et al. Object-aware regularization for addressing causal confusion in imitation learning[J]. Advances in Neural Information Processing Systems, 2021, 34: 3029-3042.
[18] Bica I, Jarrett D, van der Schaar M. Invariant causal imitation learning for generalizable policies[J]. Advances in Neural Information Processing Systems, 2021, 34: 3952-3964.
[19] Zhang P, Liu F, Chen Z, et al. Deep Reinforcement Learning with Causality-based Intrinsic Reward[J]. 2020.
[20] Mesnard T, Weber T, Viola F, et al. Counterfactual credit assignment in model-free reinforcement learning[J]. arXiv preprint arXiv:2011.09464, 2020.
[21] Li H, Principe J. Speeding Up Reinforcement Learning by Exploiting Causality in Reward Sequences[C]//2021 International Joint Conference on Neural Networks (IJCNN). IEEE, 2021: 1-6.
[22] Pitis S, Creager E, Garg A. Counterfactual data augmentation using locally factored dynamics[J]. Advances in Neural Information Processing Systems, 2020, 33: 3976-3990.
[23] Eghbal-zadeh H, Henkel F, Widmer G. Learning to infer unseen contexts in causal contextual reinforcement learning[J]. Proceedings of the Self-Supervision for Reinforcement Learning, 2021.
[24] Herlau T, Larsen R. Reinforcement learning of causal variables using mediation analysis[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2022, 36(6): 6910-6917.
[25] Lu C, Hernández-Lobato J M, Schölkopf B. Invariant causal representation learning for generalization in imitation and reinforcement learning[C]//ICLR2022 Workshop on the Elements of Reasoning: Objects, Structure and Causality. 2022.
[26] Li Y, Zhang D, Yin F, et al. Cleaning robot operation decision based on causal reasoning and attribute learning[C]//2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2020: 6878-6885.
[27] Cao Y, Li B, Li Q, et al. Reasoning Operational Decisions for Robots via Time Series Causal Inference[C]//2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2021: 6124-6131.
[28] Sun H, Wang T. Toward Causal-Aware RL: State-Wise Action-Refined Temporal Difference[J]. arXiv preprint arXiv:2201.00354, 2022.
[29] Mutti M, De Santi R, Rossi E, et al. Provably efficient causal model-based reinforcement learning for systematic generalization[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2023, 37(8): 9251-9259.
[30] Gasse M, Grasset D, Gaudron G, et al. Causal reinforcement learning using observational and interventional data[J]. arXiv preprint arXiv:2106.14421, 2021.
[31] Lee T E, Zhao J A, Sawhney A S, et al. Causal reasoning in simulation for structure and transfer learning of robot manipulation policies[C]//2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2021: 4776-4782.
[32] Lee T E, Vats S, Girdhar S, et al. SCALE: Causal Learning and Discovery of Robot Manipulation Skills using Simulation[C]//7th Annual Conference on Robot Learning. 2023.
[33] Liang J, Boularias A. Learning Transition Models with Time-delayed Causal Relations[C]//2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2020: 8087-8093.
[34] Buesing L, Weber T, Zwols Y, et al. Woulda, coulda, shoulda: Counterfactually-guided policy search[J]. arXiv preprint arXiv:1811.06272, 2018.
[35] Yang C H H, Danny I, Hung T, et al. Causal inference q-network: Toward resilient reinforcement learning[C]//Self-Supervision for Reinforcement Learning Workshop-ICLR 2021. 2021.
[36] Rezende D J, Danihelka I, Papamakarios G, et al. Causally correct partial models for reinforcement learning[J]. arXiv preprint arXiv:2002.02836, 2020.
[37] Learning Causal Dynamics Models in Object-Oriented Environments


# Multi-Agent RL
[1] Grimbly S J, Shock J, Pretorius A. Causal multi-agent reinforcement learning: Review and open problems[J]. arXiv preprint arXiv:2111.06721, 2021.


# Other regime
[1] Baradel F, Neverova N, Mille J, et al. Cophy: Counterfactual learning of physical dynamics[J]. arXiv preprint arXiv:1909.12000, 2019.
[2] Sancaktar C, Blaes S, Martius G. Curious exploration via structured world models yields zero-shot object manipulation[J]. Advances in Neural Information Processing Systems, 2022, 35: 24170-24183.
[3] Li Z, Zhu X, Lei Z, et al. Deconfounding Physical Dynamics with Global Causal Relation and Confounder Transmission for Counterfactual Prediction[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2022, 36(2): 1536-1545.

# benchmark
[1] Ahmed O, Träuble F, Goyal A, et al. Causalworld: A robotic manipulation benchmark for causal structure and transfer learning[J]. arXiv preprint arXiv:2010.04296, 2020.

# Book
[1] Luczkow V. Structural Causal Models for Reinforcement Learning[M]. McGill University (Canada), 2021.

